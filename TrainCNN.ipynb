{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTjClTUtko3u",
        "colab_type": "code",
        "outputId": "487c5f41-5721-4069-80a1-92fa84b935c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9YA2TVakyKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/TrainBienSo/charTrainset.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLHdR83ak_rU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "mypath= \"/tmp/charTrainset/\"\n",
        "characters=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\n",
        "           \"K\",\"L\",\"M\",\"N\",\"P\",\"R\",\"S\",\"T\",\"U\",\"V\",\"X\",\"Y\",\"Z\"]\n",
        "data=[]\n",
        "for i,character in enumerate(characters):\n",
        "    mypathAdded=mypath+character\n",
        "    file_names=[f for f in listdir(mypathAdded) if isfile(join(mypathAdded, f))]\n",
        "    for name in file_names:\n",
        "        img=cv2.imread(mypathAdded+\"/\"+name,0)\n",
        "        ret,img = cv2.threshold(img,50,255,cv2.THRESH_BINARY)\n",
        "        data.append([img,i])\n",
        "np.random.shuffle(data)\n",
        "x_data=[]\n",
        "y_data=[]\n",
        "for [x, y] in data:\n",
        "    x_data.append(x)\n",
        "    y_data.append(y)\n",
        "x_data=np.reshape(x_data,[-1,28,12,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gcm13lx_lf3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def CNN_Model(input_shape):\n",
        "    model=tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(filters=32,\n",
        "                                     kernel_size=(3,3),\n",
        "                                     activation='relu',\n",
        "                                     input_shape = input_shape\n",
        "                                    ))\n",
        "    model.add(tf.keras.layers.Conv2D(filters=64,\n",
        "                                     kernel_size=(3,3),\n",
        "                                     activation='relu'\n",
        "                                    ))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(units=128,\n",
        "                                    activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(units=31,\n",
        "                                    activation='softmax'))\n",
        "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, \n",
        "                  optimizer=tf.keras.optimizers.Adam(), \n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40E4d1GnsHAx",
        "colab_type": "code",
        "outputId": "d1392868-d6d0-45c1-95ff-3f22b8bdd766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "model=CNN_Model((28,12,1))\n",
        "print(model.summary())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0723 14:57:24.359290 140075587225472 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 10, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 8, 64)         18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 4, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 4, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               393344    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 31)                3999      \n",
            "=================================================================\n",
            "Total params: 416,159\n",
            "Trainable params: 416,159\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Vfdv9GsSI_",
        "colab_type": "code",
        "outputId": "301f543d-28d8-4c55-b601-ecc13214cf98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from time import time\n",
        "import os\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "tensorboard= TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
        "\n",
        "callbacks= [tensorboard]\n",
        "\n",
        "history=model.fit(x_data, y_data, \n",
        "                  batch_size=10, \n",
        "                  epochs=100, \n",
        "                  validation_data=(x_data, y_data), \n",
        "                  shuffle=True,\n",
        "                  callbacks=callbacks)\n",
        "model.save(\"model.h5\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1076 samples, validate on 1076 samples\n",
            "Epoch 1/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0363 - acc: 0.9870 - val_loss: 0.0020 - val_acc: 0.9991\n",
            "Epoch 2/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0909 - acc: 0.9833 - val_loss: 6.0264e-06 - val_acc: 1.0000\n",
            "Epoch 3/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0218 - acc: 0.9926 - val_loss: 9.5942e-08 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0737 - acc: 0.9888 - val_loss: 0.0026 - val_acc: 0.9991\n",
            "Epoch 5/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0539 - acc: 0.9916 - val_loss: 2.6821e-04 - val_acc: 1.0000\n",
            "Epoch 6/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0910 - acc: 0.9842 - val_loss: 5.2321e-05 - val_acc: 1.0000\n",
            "Epoch 7/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0966 - acc: 0.9777 - val_loss: 0.0011 - val_acc: 0.9991\n",
            "Epoch 8/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0662 - acc: 0.9879 - val_loss: 1.0810e-04 - val_acc: 1.0000\n",
            "Epoch 9/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0663 - acc: 0.9861 - val_loss: 1.8380e-06 - val_acc: 1.0000\n",
            "Epoch 10/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0460 - acc: 0.9907 - val_loss: 0.0015 - val_acc: 0.9991\n",
            "Epoch 11/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0378 - acc: 0.9907 - val_loss: 5.1761e-06 - val_acc: 1.0000\n",
            "Epoch 12/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0582 - acc: 0.9842 - val_loss: 6.0543e-06 - val_acc: 1.0000\n",
            "Epoch 13/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0275 - acc: 0.9916 - val_loss: 6.5778e-06 - val_acc: 1.0000\n",
            "Epoch 14/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0212 - acc: 0.9935 - val_loss: 1.4083e-06 - val_acc: 1.0000\n",
            "Epoch 15/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0669 - acc: 0.9861 - val_loss: 1.3372e-04 - val_acc: 1.0000\n",
            "Epoch 16/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0686 - acc: 0.9842 - val_loss: 1.0578e-05 - val_acc: 1.0000\n",
            "Epoch 17/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0480 - acc: 0.9888 - val_loss: 4.7196e-08 - val_acc: 1.0000\n",
            "Epoch 18/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0420 - acc: 0.9851 - val_loss: 4.6588e-06 - val_acc: 1.0000\n",
            "Epoch 19/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0309 - acc: 0.9898 - val_loss: 5.1096e-06 - val_acc: 1.0000\n",
            "Epoch 20/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0752 - acc: 0.9842 - val_loss: 8.2527e-07 - val_acc: 1.0000\n",
            "Epoch 21/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0235 - acc: 0.9907 - val_loss: 4.5994e-05 - val_acc: 1.0000\n",
            "Epoch 22/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0423 - acc: 0.9907 - val_loss: 3.5493e-05 - val_acc: 1.0000\n",
            "Epoch 23/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0394 - acc: 0.9898 - val_loss: 3.4229e-05 - val_acc: 1.0000\n",
            "Epoch 24/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0429 - acc: 0.9898 - val_loss: 8.3976e-08 - val_acc: 1.0000\n",
            "Epoch 25/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0435 - acc: 0.9916 - val_loss: 2.0957e-05 - val_acc: 1.0000\n",
            "Epoch 26/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0434 - acc: 0.9879 - val_loss: 1.0887e-06 - val_acc: 1.0000\n",
            "Epoch 27/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0372 - acc: 0.9888 - val_loss: 1.1004e-05 - val_acc: 1.0000\n",
            "Epoch 28/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0353 - acc: 0.9870 - val_loss: 2.8427e-07 - val_acc: 1.0000\n",
            "Epoch 29/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0334 - acc: 0.9861 - val_loss: 3.8798e-04 - val_acc: 1.0000\n",
            "Epoch 30/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0639 - acc: 0.9823 - val_loss: 6.3202e-06 - val_acc: 1.0000\n",
            "Epoch 31/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0745 - acc: 0.9842 - val_loss: 3.3191e-07 - val_acc: 1.0000\n",
            "Epoch 32/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0603 - acc: 0.9907 - val_loss: 9.7478e-06 - val_acc: 1.0000\n",
            "Epoch 33/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0324 - acc: 0.9926 - val_loss: 1.4923e-07 - val_acc: 1.0000\n",
            "Epoch 34/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0398 - acc: 0.9916 - val_loss: 2.9914e-04 - val_acc: 1.0000\n",
            "Epoch 35/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0771 - acc: 0.9861 - val_loss: 7.3452e-08 - val_acc: 1.0000\n",
            "Epoch 36/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0210 - acc: 0.9963 - val_loss: 0.0135 - val_acc: 0.9972\n",
            "Epoch 37/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0582 - acc: 0.9888 - val_loss: 9.6687e-07 - val_acc: 1.0000\n",
            "Epoch 38/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0228 - acc: 0.9926 - val_loss: 7.7218e-08 - val_acc: 1.0000\n",
            "Epoch 39/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0684 - acc: 0.9888 - val_loss: 1.0360e-06 - val_acc: 1.0000\n",
            "Epoch 40/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0310 - acc: 0.9926 - val_loss: 3.0056e-07 - val_acc: 1.0000\n",
            "Epoch 41/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0291 - acc: 0.9954 - val_loss: 1.1875e-04 - val_acc: 1.0000\n",
            "Epoch 42/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0319 - acc: 0.9926 - val_loss: 4.4834e-06 - val_acc: 1.0000\n",
            "Epoch 43/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0468 - acc: 0.9916 - val_loss: 2.0087e-05 - val_acc: 1.0000\n",
            "Epoch 44/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0547 - acc: 0.9907 - val_loss: 1.2664e-06 - val_acc: 1.0000\n",
            "Epoch 45/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0339 - acc: 0.9898 - val_loss: 6.5335e-06 - val_acc: 1.0000\n",
            "Epoch 46/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0307 - acc: 0.9944 - val_loss: 3.6968e-07 - val_acc: 1.0000\n",
            "Epoch 47/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0641 - acc: 0.9861 - val_loss: 1.6994e-07 - val_acc: 1.0000\n",
            "Epoch 48/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0361 - acc: 0.9879 - val_loss: 3.1461e-07 - val_acc: 1.0000\n",
            "Epoch 49/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0520 - acc: 0.9861 - val_loss: 2.3563e-04 - val_acc: 1.0000\n",
            "Epoch 50/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0449 - acc: 0.9879 - val_loss: 1.1200e-06 - val_acc: 1.0000\n",
            "Epoch 51/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0324 - acc: 0.9935 - val_loss: 2.1192e-07 - val_acc: 1.0000\n",
            "Epoch 52/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0826 - acc: 0.9833 - val_loss: 0.0020 - val_acc: 0.9991\n",
            "Epoch 53/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0622 - acc: 0.9879 - val_loss: 5.1932e-07 - val_acc: 1.0000\n",
            "Epoch 54/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0589 - acc: 0.9861 - val_loss: 2.2249e-05 - val_acc: 1.0000\n",
            "Epoch 55/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0240 - acc: 0.9935 - val_loss: 1.3102e-05 - val_acc: 1.0000\n",
            "Epoch 56/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0382 - acc: 0.9879 - val_loss: 7.8113e-07 - val_acc: 1.0000\n",
            "Epoch 57/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0777 - acc: 0.9842 - val_loss: 2.5204e-07 - val_acc: 1.0000\n",
            "Epoch 58/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0541 - acc: 0.9888 - val_loss: 2.1048e-06 - val_acc: 1.0000\n",
            "Epoch 59/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0526 - acc: 0.9907 - val_loss: 2.8526e-07 - val_acc: 1.0000\n",
            "Epoch 60/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0455 - acc: 0.9916 - val_loss: 5.6507e-07 - val_acc: 1.0000\n",
            "Epoch 61/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0315 - acc: 0.9916 - val_loss: 1.5954e-08 - val_acc: 1.0000\n",
            "Epoch 62/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0314 - acc: 0.9935 - val_loss: 2.4927e-08 - val_acc: 1.0000\n",
            "Epoch 63/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0313 - acc: 0.9888 - val_loss: 2.3808e-07 - val_acc: 1.0000\n",
            "Epoch 64/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0626 - acc: 0.9879 - val_loss: 1.6635e-06 - val_acc: 1.0000\n",
            "Epoch 65/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0418 - acc: 0.9898 - val_loss: 3.8160e-05 - val_acc: 1.0000\n",
            "Epoch 66/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0418 - acc: 0.9898 - val_loss: 0.0066 - val_acc: 0.9981\n",
            "Epoch 67/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0438 - acc: 0.9888 - val_loss: 8.9958e-06 - val_acc: 1.0000\n",
            "Epoch 68/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0680 - acc: 0.9833 - val_loss: 2.8583e-06 - val_acc: 1.0000\n",
            "Epoch 69/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0446 - acc: 0.9861 - val_loss: 4.6635e-06 - val_acc: 1.0000\n",
            "Epoch 70/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0806 - acc: 0.9823 - val_loss: 2.4019e-07 - val_acc: 1.0000\n",
            "Epoch 71/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0397 - acc: 0.9926 - val_loss: 7.3943e-06 - val_acc: 1.0000\n",
            "Epoch 72/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0431 - acc: 0.9926 - val_loss: 2.1558e-05 - val_acc: 1.0000\n",
            "Epoch 73/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0292 - acc: 0.9879 - val_loss: 2.5790e-07 - val_acc: 1.0000\n",
            "Epoch 74/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0889 - acc: 0.9814 - val_loss: 4.9633e-08 - val_acc: 1.0000\n",
            "Epoch 75/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0233 - acc: 0.9916 - val_loss: 4.6974e-08 - val_acc: 1.0000\n",
            "Epoch 76/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0227 - acc: 0.9916 - val_loss: 2.5911e-07 - val_acc: 1.0000\n",
            "Epoch 77/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0178 - acc: 0.9935 - val_loss: 5.6817e-07 - val_acc: 1.0000\n",
            "Epoch 78/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0176 - acc: 0.9935 - val_loss: 2.1471e-06 - val_acc: 1.0000\n",
            "Epoch 79/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0806 - acc: 0.9861 - val_loss: 1.3034e-06 - val_acc: 1.0000\n",
            "Epoch 80/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0250 - acc: 0.9916 - val_loss: 2.4752e-06 - val_acc: 1.0000\n",
            "Epoch 81/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0491 - acc: 0.9926 - val_loss: 7.7219e-08 - val_acc: 1.0000\n",
            "Epoch 82/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0267 - acc: 0.9935 - val_loss: 5.7795e-06 - val_acc: 1.0000\n",
            "Epoch 83/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0086 - acc: 0.9963 - val_loss: 6.4922e-08 - val_acc: 1.0000\n",
            "Epoch 84/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0481 - acc: 0.9888 - val_loss: 4.2764e-08 - val_acc: 1.0000\n",
            "Epoch 85/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0542 - acc: 0.9870 - val_loss: 3.9048e-07 - val_acc: 1.0000\n",
            "Epoch 86/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0943 - acc: 0.9814 - val_loss: 1.7843e-06 - val_acc: 1.0000\n",
            "Epoch 87/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0286 - acc: 0.9916 - val_loss: 1.4972e-04 - val_acc: 1.0000\n",
            "Epoch 88/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0917 - acc: 0.9861 - val_loss: 9.7883e-06 - val_acc: 1.0000\n",
            "Epoch 89/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0571 - acc: 0.9898 - val_loss: 4.7231e-05 - val_acc: 1.0000\n",
            "Epoch 90/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0221 - acc: 0.9944 - val_loss: 8.0431e-08 - val_acc: 1.0000\n",
            "Epoch 91/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0312 - acc: 0.9879 - val_loss: 2.9964e-07 - val_acc: 1.0000\n",
            "Epoch 92/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0307 - acc: 0.9944 - val_loss: 2.1050e-09 - val_acc: 1.0000\n",
            "Epoch 93/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0416 - acc: 0.9916 - val_loss: 3.5785e-08 - val_acc: 1.0000\n",
            "Epoch 94/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0693 - acc: 0.9888 - val_loss: 2.8635e-07 - val_acc: 1.0000\n",
            "Epoch 95/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0589 - acc: 0.9879 - val_loss: 1.9277e-08 - val_acc: 1.0000\n",
            "Epoch 96/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0396 - acc: 0.9944 - val_loss: 4.5312e-08 - val_acc: 1.0000\n",
            "Epoch 97/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.1137 - acc: 0.9796 - val_loss: 1.8923e-06 - val_acc: 1.0000\n",
            "Epoch 98/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.1069 - acc: 0.9842 - val_loss: 1.8391e-08 - val_acc: 1.0000\n",
            "Epoch 99/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.1062 - acc: 0.9870 - val_loss: 1.7402e-05 - val_acc: 1.0000\n",
            "Epoch 100/100\n",
            "1076/1076 [==============================] - 2s 2ms/sample - loss: 0.0711 - acc: 0.9888 - val_loss: 1.5510e-08 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}